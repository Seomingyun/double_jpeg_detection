# -*- coding: utf-8 -*-
"""net4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fh61vuzRV1RLDeGSQegX7fYYaNb5OOaV
"""

import torch
import numpy as np
import torch.nn.functional as F
from DCTbasis import load_DCT_basis_torch
import easydict
import torch.nn as nn 



class Net4(nn.Module): 
    def __init__(self, input_size, hidden_size, output_size, device, n_layers=1):
        super(Net4, self).__init__()
        self.dct_basis = load_DCT_basis_torch().float()
        self.dct_basis = self.dct_basis.to(device)
 
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.n_layers = n_layers
 
        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=hidden_size, kernel_size=5)
        self.bn1 = nn.BatchNorm1d(hidden_size)
        self.pool1 = nn.AvgPool1d(kernel_size=2)
 
        self.conv2 = nn.Conv1d(in_channels=hidden_size, out_channels=hidden_size, kernel_size=5)
        self.bn2 = nn.BatchNorm1d(hidden_size)
        self.pool2 = nn.AvgPool1d(kernel_size=2)
 
        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, batch_first=True, bidirectional=True, dropout=0.3)
        
        self.fc1 = nn.Linear(2*hidden_size, 128)
        self.fc2 = nn.Linear(128, 2)
 
    def forward(self, x, qvectors, hidden):
        # feature extraction
        with torch.no_grad(): # 기록 추적 및 메모리 사용 방지
            gamma=1e+06 # 10^6
            x = F.conv2d(x, self.dct_basis, stride=8) 
            for b in range(-60, 61): 
                x_ = torch.sum(torch.sigmoid(gamma*(x-b)), axis=[2,3])/1024 
                x_ = torch.unsqueeze(x_, axis=1) 
                if b==-60:
                    features = x_
                else:
                    features = torch.cat([features, x_], axis=1)
            features = features[:, 0:120, :] - features[:, 1:121, :]
            features = torch.squeeze(features, axis=1)
        
        output = torch.relu(self.conv1(features))
        output = torch.relu(self.bn1(output))
        output = self.pool1(output)
 
        output = torch.relu(self.conv2(output))
        output = torch.relu(self.bn2(output))
        output = self.pool2(output)
 
        # output = output.transpose(1, 2).transpose(0, 1)
        output = output.transpose(1, 2)
        # print(output.shape)
 
        # output = torch.tanh(output)
 
        output, hidden = self.gru(output, hidden)
        
        # conv_seq_len = output.size(0)
        # output = output.view(32, self.hidden_size * conv_seq_len)
        # print(output.shape)
 
        output_flat = output[:, -1, :]
        output = torch.cat([qvectors, output_flat], axis=1)
        output = output_flat
        # print(output.shape)
 
        output = torch.relu(self.fc1(output))
        output = self.fc2(output)
 
        # output = torch.tanh(self.fc(output))
 
        # output = output.view(32, self.output_size)
 
        return output

class CNN_GRU(nn.Module): 
    def __init__(self, input_size, hidden_size, output_size, device, n_layers=1):
        super(CNN_GRU, self).__init__()
        self.dct_basis = load_DCT_basis_torch().float()
        self.dct_basis = self.dct_basis.to(device)
 
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.n_layers = n_layers
 
        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=hidden_size, kernel_size=5)
        self.bn1 = nn.BatchNorm1d(hidden_size)
        self.pool1 = nn.AvgPool1d(kernel_size=2)
 
        self.conv2 = nn.Conv1d(in_channels=hidden_size, out_channels=hidden_size, kernel_size=5)
        self.bn2 = nn.BatchNorm1d(hidden_size)
        self.pool2 = nn.AvgPool1d(kernel_size=2)
 
        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, batch_first=True, bidirectional=True, dropout=0.3)
        
        self.fc1 = nn.Linear(2*hidden_size, 128)
        self.fc2 = nn.Linear(128, 2)
 
    def forward(self, x, qvectors, hidden):
        # feature extraction
        with torch.no_grad(): # 기록 추적 및 메모리 사용 방지
            gamma=1e+06 # 10^6
            x = F.conv2d(x, self.dct_basis, stride=8) 
            for b in range(-60, 61): 
                x_ = torch.sum(torch.sigmoid(gamma*(x-b)), axis=[2,3])/1024 
                x_ = torch.unsqueeze(x_, axis=1) 
                if b==-60:
                    features = x_
                else:
                    features = torch.cat([features, x_], axis=1)
            features = features[:, 0:120, :] - features[:, 1:121, :]
            features = torch.squeeze(features, axis=1)
        
        output = torch.relu(self.conv1(features))
        output = torch.relu(self.bn1(output))
        output = self.pool1(output)
 
        output = torch.relu(self.conv2(output))
        output = torch.relu(self.bn2(output))
        output = self.pool2(output)
 
        # output = output.transpose(1, 2).transpose(0, 1)
        output = output.transpose(1, 2)
        # print(output.shape)
 
        # output = torch.tanh(output)
 
        output, hidden = self.gru(output, hidden)
        
        # conv_seq_len = output.size(0)
        # output = output.view(32, self.hidden_size * conv_seq_len)
        # print(output.shape)
 
        output_flat = output[:, -1, :]
        output = torch.cat([qvectors, output_flat], axis=1)
        output = output_flat
        # print(output.shape)
 
        output = torch.relu(self.fc1(output))
        output = self.fc2(output)
 
        # output = torch.tanh(self.fc(output))
 
        # output = output.view(32, self.output_size)
 
        return output